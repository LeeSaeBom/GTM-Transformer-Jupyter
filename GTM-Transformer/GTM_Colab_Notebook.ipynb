{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# 📊 GTM (Google Trends Transformer) 패션 매출 예측 - Google Colab\n",
    "\n",
    "이 노트북은 Google Colab에서 GTM 모델을 실행하기 위해 최적화되었습니다.\n",
    "\n",
    "## 🎯 모델 개요\n",
    "- **멀티모달 입력**: 이미지, 텍스트(카테고리/색상/소재), Google Trends, 시간적 특성\n",
    "- **출력**: 향후 12개월 매출 예측\n",
    "- **아키텍처**: Transformer 기반 + ResNet50 + BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. 🔧 환경 설정 및 Google Drive 마운트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Google Drive 마운트\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 작업 디렉토리 설정\n",
    "import os\n",
    "os.chdir('/content')\n",
    "\n",
    "# GPU 확인\n",
    "import torch\n",
    "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU 메모리: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_packages"
   },
   "outputs": [],
   "source": "# 단계적 패키지 설치 (에러 방지)\nimport os\nimport subprocess\nimport sys\n\ndef install_package(package):\n    try:\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"--quiet\"])\n        print(f\"✅ {package} 설치 완료\")\n        return True\n    except subprocess.CalledProcessError as e:\n        print(f\"❌ {package} 설치 실패: {e}\")\n        return False\n\n# 1. 기본 의존성부터 설치\nprint(\"🔧 기본 패키지 설치 중...\")\ninstall_package(\"wheel\")\ninstall_package(\"setuptools\")\n\n# 2. tokenizers 문제 해결 - 사전 컴파일된 버전 사용\nprint(\"🔧 tokenizers 설치 중...\")\n!pip install tokenizers --no-build-isolation --quiet\n\n# 3. transformers 설치\nprint(\"🔧 transformers 설치 중...\")\ninstall_package(\"transformers==4.21.0\")\n\n# 4. PyTorch Lightning 설치 (Colab 기본 PyTorch와 호환되는 버전)\nprint(\"🔧 PyTorch Lightning 설치 중...\")\ninstall_package(\"pytorch-lightning==1.9.5\")  # 더 안정적인 버전 사용\n\n# 5. 기타 필요 패키지\nprint(\"🔧 추가 패키지 설치 중...\")\ninstall_package(\"wandb\")\ninstall_package(\"scikit-learn\")\n\nprint(\"📦 모든 패키지 설치 완료!\")\n\n# 이제 import 테스트\ntry:\n    import torch\n    import pytorch_lightning as pl\n    import transformers\n    import pandas as pd\n    import numpy as np\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    from pathlib import Path\n    import warnings\n    warnings.filterwarnings('ignore')\n    \n    from pytorch_lightning.callbacks import ModelCheckpoint\n    from pytorch_lightning.loggers import CSVLogger\n    \n    print(f\"✅ PyTorch: {torch.__version__}\")\n    print(f\"✅ PyTorch Lightning: {pl.__version__}\")\n    print(f\"✅ Transformers: {transformers.__version__}\")\n    print(f\"✅ CUDA 사용 가능: {torch.cuda.is_available()}\")\n    \nexcept ImportError as e:\n    print(f\"❌ Import 실패: {e}\")\n    print(\"⚠️ 런타임을 재시작한 후 다음 대안 코드를 실행하세요:\")\n    print(\"!pip uninstall -y tokenizers transformers pytorch-lightning\")\n    print(\"!pip install pytorch-lightning==1.9.5 transformers==4.21.0 --no-cache-dir\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone_repo"
   },
   "source": [
    "## 2. 🔄 GTM-Transformer 코드 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_code"
   },
   "outputs": [],
   "source": "# 수정된 GTM-Transformer 코드 사용 (Google Drive에서 복사)\n# git clone 대신 이미 수정된 코드를 Google Drive에서 복사\n\nprint(\"🔍 Google Drive에서 수정된 GTM-Transformer 코드 확인...\")\n\n# Google Drive의 GTM-Transformer 경로 (사용자가 업로드한 경로)\nDRIVE_CODE_PATH = '/content/drive/MyDrive/GTM-Transformer/'  # 수정된 코드 경로\nDRIVE_DATASET_PATH = '/content/drive/MyDrive/GTM-dataset/'   # 데이터셋 경로\n\n# GTM-Transformer 폴더가 있는지 확인\nif os.path.exists(DRIVE_CODE_PATH):\n    print(\"✅ 수정된 GTM-Transformer 코드를 찾았습니다!\")\n    print(\"📂 코드 구조:\")\n    !ls -la \"/content/drive/MyDrive/GTM-Transformer/\"\n    \n    # 코드를 Colab 작업 디렉토리로 복사\n    print(\"🔄 코드 복사 중...\")\n    !cp -r \"/content/drive/MyDrive/GTM-Transformer\" \"/content/\"\n    os.chdir('/content/GTM-Transformer')\n    \n    print(\"✅ 코드 복사 완료!\")\n    \n    # 필요한 디렉토리 생성\n    !mkdir -p checkpoints logs saved_models\n    \nelse:\n    print(\"❌ GTM-Transformer 폴더를 찾을 수 없습니다.\")\n    print(\"📋 업로드 방법:\")\n    print(\"1. 로컬의 수정된 GTM-Transformer 폴더 전체를 Google Drive에 업로드\")\n    print(\"2. Google Drive 경로: /content/drive/MyDrive/GTM-Transformer/\")\n    print(\"3. 폴더 구조 확인:\")\n    print(\"   GTM-Transformer/\")\n    print(\"   ├── models/\")\n    print(\"   ├── utils/\") \n    print(\"   ├── train.py\")\n    print(\"   └── ...\")\n\n# 데이터셋 경로도 확인\nif os.path.exists(DRIVE_DATASET_PATH):\n    print(\"✅ 데이터셋도 확인되었습니다!\")\nelse:\n    print(\"⚠️ 데이터셋 폴더도 확인해주세요: /content/drive/MyDrive/GTM-dataset/\")\n\nprint(\"✅ 환경 설정 완료!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fix_code"
   },
   "source": "## 3. ✅ 코드 준비 완료 (디바이스 호환성 수정됨)\n\nGoogle Drive에서 복사한 코드는 이미 호환성 문제가 모두 수정된 버전입니다:\n- ✅ fairseq → transformers (Adafactor)\n- ✅ validation_epoch_end → on_validation_epoch_end  \n- ✅ CUDA → CPU/GPU 자동 선택\n- ✅ torch.load weights_only 파라미터\n- ✅ PyTorch Lightning 2.x 호환성\n- ✅ **GPU/CPU 디바이스 불일치 해결** (NEW!)\n\n### 🔧 최신 수정사항 (GPU/CPU 디바이스 오류 해결)\n- GTM 모델 내 모든 `.to('cpu')` 호출을 동적 디바이스 할당으로 변경\n- TextEmbedder의 word_embeddings를 올바른 디바이스로 배치\n- 마스크 생성 시 디바이스 일치성 보장\n- autoregressive 디코딩 시 텐서 디바이스 통일"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "patch_gtm"
   },
   "outputs": [],
   "source": "# 코드 확인 (선택적)\n# 수정된 코드가 제대로 복사되었는지 확인하고 싶다면 실행\n\nprint(\"🔍 주요 파일 확인:\")\n!ls -la models/\nprint(\"\\n📄 GTM.py에서 transformers import 확인:\")\n!head -10 models/GTM.py | grep -E \"(transformers|Adafactor)\"\nprint(\"\\n📄 train.py에서 weights_only 확인:\")\n!grep -n \"weights_only\" train.py | head -3\n\nprint(\"\\n✅ 모든 수정사항이 적용되어 있습니다!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_check"
   },
   "source": [
    "## 4. 📊 데이터셋 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_dataset"
   },
   "outputs": [],
   "source": "# 데이터셋 존재 확인 (축소된 데이터셋 사용)\ndataset_path = Path('/content/drive/MyDrive/GTM-dataset-small/')  # 축소된 데이터셋 경로\nrequired_files = ['train.csv', 'test.csv', 'gtrends.csv', 'category_labels.pt', 'color_labels.pt', 'fabric_labels.pt']\n\nprint(\"📂 축소된 데이터셋 파일 확인:\")\nfor file in required_files:\n    file_path = dataset_path / file\n    exists = file_path.exists()\n    if exists:\n        size = file_path.stat().st_size\n        print(f\"  ✅ {file}: {size/1024:.1f} KB\")\n    else:\n        print(f\"  ❌ {file}: 파일 없음\")\n\n# 이미지 폴더 확인\nimage_path = dataset_path / 'images'\nif image_path.exists():\n    # 하위 폴더별 이미지 수 확인\n    total_images = 0\n    print(f\"  📁 이미지 폴더 구조:\")\n    for subdir in sorted(image_path.iterdir()):\n        if subdir.is_dir():\n            subdir_images = list(subdir.glob('*.png')) + list(subdir.glob('*.jpg'))\n            print(f\"    📂 {subdir.name}: {len(subdir_images)}개\")\n            total_images += len(subdir_images)\n    print(f\"  🖼️ 총 이미지: {total_images}개\")\nelse:\n    print(f\"  ❌ images/ 폴더 없음\")\n\n# 데이터 로딩 테스트 (parse_dates 파라미터 추가)\ntry:\n    print(\"\\n🔄 축소된 데이터 로딩 테스트...\")\n    train_df = pd.read_csv(dataset_path / 'train.csv', parse_dates=['release_date'])\n    test_df = pd.read_csv(dataset_path / 'test.csv', parse_dates=['release_date'])\n    gtrends = pd.read_csv(dataset_path / 'gtrends.csv', index_col=[0], parse_dates=True)\n    \n    print(f\"\\n📊 축소된 데이터 통계:\")\n    print(f\"  - 훈련 데이터: {len(train_df):,}개 샘플 (원본의 ~1/10)\")\n    print(f\"  - 테스트 데이터: {len(test_df):,}개 샘플 (원본의 ~1/10)\")\n    print(f\"  - Google Trends: {len(gtrends):,}개 시점 (동일)\")\n    print(f\"  - 총 이미지: {total_images}개 (원본의 ~1/10)\")\n    \n    # release_date 타입 확인\n    print(f\"\\n📅 release_date 타입: {type(train_df['release_date'].iloc[0])}\")\n    print(f\"💾 예상 데이터셋 크기: ~{total_images * 0.1:.0f} MB\")\n    \n    # 카테고리 분포 확인\n    print(f\"\\n🏷️ 카테고리 분포:\")\n    category_counts = train_df['category'].value_counts()\n    for cat, count in category_counts.head(10).items():\n        print(f\"  - {cat}: {count}개\")\n    \n    # 데이터 미리보기\n    print(f\"\\n👀 축소된 훈련 데이터 첫 3행:\")\n    print(train_df[['category', 'color', 'fabric', 'release_date', 'image_path']].head(3))\n    \nexcept Exception as e:\n    print(f\"❌ 데이터 로딩 실패: {e}\")\n    print(\"\\n🔧 해결 방법:\")\n    print(\"1. 로컬에서 'dataset_small' 폴더를 'GTM-dataset-small'로 이름 변경\")\n    print(\"2. Google Drive에 'GTM-dataset-small' 폴더 업로드\")\n    print(\"3. 폴더 구조 확인:\")\n    print(\"   GTM-dataset-small/\")\n    print(\"   ├── train.csv (508 샘플)\")\n    print(\"   ├── test.csv (50 샘플)\")\n    print(\"   ├── images/ (~558개 이미지)\")\n    print(\"   └── *.pt 라벨 파일들\")\n    print(\"4. 아래 명령으로 실제 폴더 확인:\")\n    print(\"   !ls -la '/content/drive/MyDrive/GTM-dataset-small/'\")\n\nprint(f\"\\n🚀 축소된 데이터셋으로 빠른 실험 준비 완료!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_setup"
   },
   "source": "# 이미지 폴더 구조 확인 및 재구성\nimport shutil\nfrom pathlib import Path\n\nprint(\"🖼️ 이미지 폴더 구조 확인 및 수정...\")\n\ndataset_path = Path('/content/drive/MyDrive/GTM-dataset/')\nimage_path = dataset_path / 'images'\n\n# 현재 이미지 폴더 구조 확인\nprint(f\"📂 이미지 폴더: {image_path}\")\n\n# 하위 폴더들이 있는지 확인\nsubdirs = [d for d in image_path.iterdir() if d.is_dir()]\nimage_files = list(image_path.glob('*.png')) + list(image_path.glob('*.jpg'))\n\nprint(f\"  📁 하위 폴더 수: {len(subdirs)}\")\nprint(f\"  🖼️ 직접 이미지 파일 수: {len(image_files)}\")\n\nif subdirs:\n    print(\"✅ 올바른 폴더 구조가 있습니다:\")\n    for subdir in subdirs:\n        subdir_images = list(subdir.glob('*.png')) + list(subdir.glob('*.jpg'))\n        print(f\"  📁 {subdir.name}: {len(subdir_images)}개 이미지\")\nelse:\n    print(\"⚠️ 하위 폴더가 없습니다. 이미지 경로를 확인합니다...\")\n    \n    # CSV에서 실제로 사용되는 경로 패턴 확인\n    sample_paths = train_df['image_path'].head(10).tolist()\n    print(\"📋 CSV의 이미지 경로 예시:\")\n    for path in sample_paths:\n        print(f\"  - {path}\")\n    \n    # 필요한 하위 폴더들 생성 (CSV 경로 기반)\n    required_subdirs = set()\n    for path in train_df['image_path']:\n        if '/' in path:\n            subdir = path.split('/')[0]\n            required_subdirs.add(subdir)\n    \n    print(f\"\\n📁 필요한 하위 폴더들: {list(required_subdirs)}\")\n    \n    if len(image_files) > 0 and len(required_subdirs) > 0:\n        print(\"🔧 폴더 구조 재구성 중...\")\n        \n        # 하위 폴더들 생성\n        for subdir in required_subdirs:\n            (image_path / subdir).mkdir(exist_ok=True)\n            print(f\"  📁 생성: {subdir}/\")\n        \n        # 이미지 파일들을 적절한 하위 폴더로 이동\n        # 파일명 기반으로 폴더 추정 (예: PE17/00001.png -> 00001.png는 PE17 폴더에)\n        moved_count = 0\n        for img_file in image_files:\n            # CSV에서 이 파일을 참조하는 경로 찾기\n            matching_paths = train_df[train_df['image_path'].str.contains(img_file.name)]\n            if len(matching_paths) > 0:\n                csv_path = matching_paths.iloc[0]['image_path']\n                if '/' in csv_path:\n                    target_subdir = csv_path.split('/')[0]\n                    target_path = image_path / target_subdir / img_file.name\n                    \n                    if not target_path.exists():\n                        shutil.move(str(img_file), str(target_path))\n                        moved_count += 1\n        \n        print(f\"✅ {moved_count}개 이미지 파일 이동 완료!\")\n        \n        # 최종 구조 확인\n        print(\"\\n📊 최종 폴더 구조:\")\n        for subdir in (image_path).iterdir():\n            if subdir.is_dir():\n                subdir_images = list(subdir.glob('*.png')) + list(subdir.glob('*.jpg'))\n                print(f\"  📁 {subdir.name}: {len(subdir_images)}개 이미지\")\n\nprint(\"\\n✅ 이미지 폴더 구조 준비 완료!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_model"
   },
   "outputs": [],
   "source": "# 모델 import 및 설정\nsys.path.append('./models')\nfrom models.GTM import GTM\nfrom models.FCN import FCN\nfrom utils.data_multitrends import ZeroShotDataset\n\n# 하이퍼파라미터 (축소된 데이터셋용으로 조정)\nBATCH_SIZE = 8 if torch.cuda.is_available() else 4  # 더 작은 배치 크기\nEPOCHS = 5  # 빠른 실험을 위해 에포크 수 감소\nACCELERATOR = 'gpu' if torch.cuda.is_available() else 'cpu'\nDEVICES = 1\n\n# 축소된 데이터셋 경로\ndataset_path = Path('/content/drive/MyDrive/GTM-dataset-small/')\n\n# 라벨 딕셔너리 로딩 (축소된 데이터셋에서)\ncat_dict = torch.load(dataset_path / 'category_labels.pt', weights_only=False)\ncol_dict = torch.load(dataset_path / 'color_labels.pt', weights_only=False)\nfab_dict = torch.load(dataset_path / 'fabric_labels.pt', weights_only=False)\n\nprint(f\"📋 축소된 라벨 딕셔너리:\")\nprint(f\"  - 카테고리: {len(cat_dict)}개\")\nprint(f\"  - 색상: {len(col_dict)}개\") \nprint(f\"  - 소재: {len(fab_dict)}개\")\n\n# 축소된 데이터셋 생성\nprint(\"\\n🔄 축소된 훈련 데이터셋 생성 중...\")\ntrain_dataset = ZeroShotDataset(\n    train_df, \n    dataset_path / 'images',  # 축소된 이미지 경로\n    gtrends, \n    cat_dict, \n    col_dict, \n    fab_dict, \n    trend_len=52\n)\n\nprint(\"🔄 축소된 테스트 데이터셋 생성 중...\")\ntest_dataset = ZeroShotDataset(\n    test_df, \n    dataset_path / 'images',  # 축소된 이미지 경로\n    gtrends, \n    cat_dict, \n    col_dict, \n    fab_dict, \n    trend_len=52\n)\n\n# DataLoader 생성 (더 작은 배치 크기)\nprint(\"🔄 DataLoader 생성 중...\")\ntrain_loader = train_dataset.get_loader(batch_size=BATCH_SIZE, train=True)\ntest_loader = test_dataset.get_loader(batch_size=1, train=False)\n\nprint(f\"✅ 축소된 데이터 로딩 완료!\")\nprint(f\"  - 훈련 데이터: {len(train_df)}개\")\nprint(f\"  - 테스트 데이터: {len(test_df)}개\")  \nprint(f\"  - 훈련 배치 크기: {BATCH_SIZE}\")\nprint(f\"  - 테스트 배치 크기: 1\")\nprint(f\"  - 에포크: {EPOCHS}개 (빠른 실험용)\")\nprint(f\"  - 가속기: {ACCELERATOR}\")\n\n# 첫 번째 배치 구조 확인\nprint(\"\\n🔍 첫 번째 배치 구조 확인:\")\ntry:\n    sample_batch = next(iter(train_loader))\n    print(f\"  - 배치 요소 수: {len(sample_batch)}\")\n    for i, item in enumerate(sample_batch):\n        if hasattr(item, 'shape'):\n            print(f\"  - 요소 {i}: {item.shape}\")\n        else:\n            print(f\"  - 요소 {i}: {type(item)}\")\n    print(\"✅ 축소된 데이터셋 배치 구조 확인 완료!\")\n    print(f\"💡 예상 훈련 시간: ~{len(train_loader) * EPOCHS // 10} 분\")\nexcept Exception as e:\n    print(f\"❌ 배치 로딩 실패: {e}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_model"
   },
   "outputs": [],
   "source": "# GTM 모델 생성 및 설정\nprint(\"🎯 GTM 모델 생성 중...\")\n\n# GTM 모델 인스턴스 생성\nmodel = GTM(\n    embedding_dim=32,\n    hidden_dim=64,\n    output_dim=12,\n    num_heads=4,\n    num_layers=1,\n    use_text=True,\n    use_img=True,\n    cat_dict=cat_dict,\n    col_dict=col_dict,\n    fab_dict=fab_dict,\n    trend_len=52,\n    num_trends=3,\n    gpu_num=0,\n    use_encoder_mask=1,\n    autoregressive=False\n)\n\nprint(f\"✅ GTM 모델 생성 완료!\")\nprint(f\"📊 모델 파라미터: {sum(p.numel() for p in model.parameters()):,}\")\n\n# 체크포인트 및 로거 설정\ncheckpoint_callback = ModelCheckpoint(\n    dirpath='./checkpoints/',\n    filename='gtm-colab-{epoch:02d}-{val_mae:.2f}',\n    monitor='val_mae',\n    mode='min',\n    save_top_k=2,\n    verbose=True\n)\n\ncsv_logger = CSVLogger(\n    save_dir='./logs/',\n    name='gtm_colab'\n)\n\n# Trainer 설정\ntrainer = pl.Trainer(\n    devices=DEVICES,\n    accelerator=ACCELERATOR,\n    max_epochs=EPOCHS,\n    check_val_every_n_epoch=2,\n    logger=csv_logger,\n    callbacks=[checkpoint_callback],\n    enable_progress_bar=True,\n    log_every_n_steps=20\n)\n\nprint(f\"🚀 Trainer 설정 완료!\")\n\n# 🔍 Gradient 디버깅을 위한 텐서 상태 확인\nprint(\"\\n🔍 입력 텐서들의 gradient 상태 확인...\")\n\n# 첫 번째 배치 가져오기\nsample_batch = next(iter(train_loader))\nitem_sales, category, color, fabric, temporal_features, gtrends, images = sample_batch\n\nprint(\"📊 입력 텐서 gradient 상태:\")\nprint(f\"  - item_sales: requires_grad={item_sales.requires_grad}, device={item_sales.device}\")\nprint(f\"  - category: requires_grad={category.requires_grad}, device={category.device}\")\nprint(f\"  - color: requires_grad={color.requires_grad}, device={color.device}\")\nprint(f\"  - fabric: requires_grad={fabric.requires_grad}, device={fabric.device}\")\nprint(f\"  - temporal_features: requires_grad={temporal_features.requires_grad}, device={temporal_features.device}\")\nprint(f\"  - gtrends: requires_grad={gtrends.requires_grad}, device={gtrends.device}\")\nprint(f\"  - images: requires_grad={images.requires_grad}, device={images.device}\")\n\n# 모델의 각 인코더별 출력 확인\nprint(\"\\n🔧 각 인코더 출력의 gradient 상태:\")\nwith torch.no_grad():  # 일시적으로 gradient 계산 비활성화\n    img_encoding = model.image_encoder(images)\n    dummy_encoding = model.dummy_encoder(temporal_features)\n    text_encoding = model.text_encoder(category, color, fabric)\n    gtrend_encoding = model.gtrend_encoder(gtrends)\n    \n    print(f\"  - img_encoding: requires_grad={img_encoding.requires_grad}\")\n    print(f\"  - dummy_encoding: requires_grad={dummy_encoding.requires_grad}\")\n    print(f\"  - text_encoding: requires_grad={text_encoding.requires_grad}\")\n    print(f\"  - gtrend_encoding: requires_grad={gtrend_encoding.requires_grad}\")\n\n# 모델 파라미터 중 requires_grad=False인 것 찾기\nprint(\"\\n⚠️ requires_grad=False인 모델 파라미터:\")\nno_grad_params = []\nfor name, param in model.named_parameters():\n    if not param.requires_grad:\n        no_grad_params.append(name)\n\nif no_grad_params:\n    print(\"  다음 파라미터들이 requires_grad=False:\")\n    for name in no_grad_params[:10]:  # 처음 10개만 출력\n        print(f\"    - {name}\")\n    if len(no_grad_params) > 10:\n        print(f\"    ... 총 {len(no_grad_params)}개\")\nelse:\n    print(\"  ✅ 모든 모델 파라미터가 requires_grad=True\")\n\nprint(\"\\n💡 Gradient 문제 해결을 위한 조치가 적용됨:\")\nprint(\"  ✅ training_step에서 입력 텐서에 requires_grad 설정\")\nprint(\"  ✅ ResNet 일부 레이어 freeze 해제\")\nprint(\"  ✅ TextEmbedder에 gradient 활성화\")\nprint(\"\\n🎯 모델과 Trainer 준비 완료! 다음 셀에서 훈련을 시작하세요.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_model"
   },
   "outputs": [],
   "source": [
    "# 모델 훈련 실행\n",
    "print(\"🚀 GTM 모델 훈련 시작!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "trainer.fit(\n",
    "    model, \n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=test_loader\n",
    ")\n",
    "\n",
    "print(\"\\n🎉 훈련 완료!\")\n",
    "print(f\"💾 최고 모델: {checkpoint_callback.best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results"
   },
   "source": [
    "## 6. 📊 결과 분석 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize_results"
   },
   "outputs": [],
   "source": [
    "# 훈련 메트릭 시각화\n",
    "log_dir = './logs/gtm_colab/'\n",
    "version_dirs = [d for d in os.listdir(log_dir) if d.startswith('version_')]\n",
    "if version_dirs:\n",
    "    latest_version = max(version_dirs, key=lambda x: int(x.split('_')[1]))\n",
    "    metrics_path = os.path.join(log_dir, latest_version, 'metrics.csv')\n",
    "    \n",
    "    if os.path.exists(metrics_path):\n",
    "        metrics_df = pd.read_csv(metrics_path)\n",
    "        \n",
    "        # 메트릭 플롯\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Loss 플롯\n",
    "        train_loss = metrics_df.dropna(subset=['train_loss'])\n",
    "        val_loss = metrics_df.dropna(subset=['val_loss'])\n",
    "        \n",
    "        axes[0].plot(train_loss['step'], train_loss['train_loss'], label='Training Loss', alpha=0.7)\n",
    "        axes[0].plot(val_loss['step'], val_loss['val_loss'], label='Validation Loss', marker='o')\n",
    "        axes[0].set_title('📉 Training/Validation Loss')\n",
    "        axes[0].set_xlabel('Steps')\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # MAE 플롯\n",
    "        val_mae = metrics_df.dropna(subset=['val_mae'])\n",
    "        axes[1].plot(val_mae['step'], val_mae['val_mae'], label='Validation MAE', marker='s', color='red')\n",
    "        axes[1].set_title('📊 Validation MAE')\n",
    "        axes[1].set_xlabel('Steps')\n",
    "        axes[1].set_ylabel('MAE')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # 최종 성능 출력\n",
    "        if not val_mae.empty:\n",
    "            final_mae = val_mae['val_mae'].iloc[-1]\n",
    "            print(f\"🎯 최종 Validation MAE: {final_mae:.2f}\")\n",
    "    else:\n",
    "        print(\"⚠️ 메트릭 파일을 찾을 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_predictions"
   },
   "outputs": [],
   "source": [
    "# 모델 예측 테스트\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample_batch = next(iter(test_loader))\n",
    "    item_sales, category, color, fabric, temporal_features, gtrends_batch, images = sample_batch\n",
    "    \n",
    "    # 예측 수행\n",
    "    predictions, attention_weights = model(category, color, fabric, temporal_features, gtrends_batch, images)\n",
    "    \n",
    "    # 정규화 해제\n",
    "    actual_sales = item_sales * 1065\n",
    "    predicted_sales = predictions * 1065\n",
    "\n",
    "# 예측 시각화\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(min(4, len(predictions))):\n",
    "    actual = actual_sales[i].cpu().numpy()\n",
    "    predicted = predicted_sales[i].cpu().numpy()\n",
    "    \n",
    "    axes[i].plot(months, actual, label='실제 매출', marker='o', linewidth=2)\n",
    "    axes[i].plot(months, predicted, label='예측 매출', marker='s', linewidth=2, alpha=0.8)\n",
    "    axes[i].set_title(f'Colab 예측 결과 {i+1}')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    mae = np.mean(np.abs(actual - predicted))\n",
    "    axes[i].text(0.02, 0.98, f'MAE: {mae:.1f}', transform=axes[i].transAxes, \n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7),\n",
    "                verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 전체 성능\n",
    "overall_mae = np.mean(np.abs(actual_sales.cpu().numpy() - predicted_sales.cpu().numpy()))\n",
    "print(f\"🔮 Colab 전체 예측 MAE: {overall_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save_model"
   },
   "source": [
    "## 7. 💾 모델 저장 (Google Drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_to_drive"
   },
   "outputs": [],
   "source": [
    "# Google Drive에 결과 저장\n",
    "drive_save_path = '/content/drive/MyDrive/GTM-Results/'\n",
    "os.makedirs(drive_save_path, exist_ok=True)\n",
    "\n",
    "# 최고 모델을 Google Drive에 복사\n",
    "if checkpoint_callback.best_model_path:\n",
    "    import shutil\n",
    "    best_model_name = f\"gtm_colab_best_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}.ckpt\"\n",
    "    shutil.copy2(checkpoint_callback.best_model_path, drive_save_path + best_model_name)\n",
    "    print(f\"💾 최고 모델 저장: {drive_save_path + best_model_name}\")\n",
    "\n",
    "# 메트릭 CSV도 저장\n",
    "if os.path.exists(metrics_path):\n",
    "    shutil.copy2(metrics_path, drive_save_path + 'training_metrics.csv')\n",
    "    print(f\"📊 훈련 메트릭 저장: {drive_save_path}training_metrics.csv\")\n",
    "\n",
    "# 노트북도 저장\n",
    "!cp /content/colabtools/notebook.ipynb \"{drive_save_path}GTM_Colab_Executed.ipynb\"\n",
    "print(f\"📓 실행된 노트북 저장: {drive_save_path}GTM_Colab_Executed.ipynb\")\n",
    "\n",
    "print(\"\\n✅ 모든 결과가 Google Drive에 저장되었습니다!\")\n",
    "print(f\"📂 저장 위치: {drive_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": "## 📋 Colab 실행 가이드 (축소된 데이터셋 버전)\n\n### ✅ 실행 전 준비사항\n\n**1. 로컬에서 축소된 데이터셋 생성:**\n```bash\n# GTM-Transformer 폴더에서 실행\npython simple_sample.py    # CSV 파일 1/10로 샘플링  \npython copy_images.py      # 필요한 이미지만 복사\n```\n\n**2. Google Drive에 업로드할 폴더:**\n```\n/content/drive/MyDrive/\n├── GTM-Transformer/          # 로컬에서 수정된 전체 코드\n└── GTM-dataset-small/        # 축소된 데이터셋 (NEW!)\n    ├── train.csv            # 508개 샘플 (원본의 1/10)\n    ├── test.csv             # 50개 샘플 (원본의 1/10)  \n    ├── gtrends.csv          # 동일\n    ├── category_labels.pt\n    ├── color_labels.pt\n    ├── fabric_labels.pt\n    └── images/              # 558개 이미지 (원본의 1/10)\n        ├── AI17/ (~88개)\n        ├── AI18/ (~101개)\n        ├── AI19/ (~108개)\n        ├── PE17/ (~96개)\n        ├── PE18/ (~76개)\n        └── PE19/ (~89개)\n```\n\n**3. GPU 설정:** \n- Colab에서 런타임 → 런타임 유형 변경 → GPU 선택\n\n### 🚀 실행 순서 (축소된 데이터셋)\n1. **패키지 설치** (자동 에러 처리)\n2. **Google Drive 마운트 및 코드/데이터셋 확인**\n3. **수정된 코드 복사** \n4. **축소된 데이터 로딩 및 빠른 모델 훈련**\n5. **결과 분석 및 Google Drive 저장**\n\n### 💡 축소된 데이터셋의 장점\n- ✅ **10배 빠른 실행** (~5-10분 내 완료)\n- ✅ **GPU 메모리 부족 문제 해결** \n- ✅ **Colab 세션 시간 제한 여유**\n- ✅ **빠른 프로토타이핑** 가능\n- ✅ **동일한 모델 아키텍처** 테스트\n\n### ⚙️ 수정된 하이퍼파라미터\n- **배치 크기**: 8 (GPU) / 4 (CPU)\n- **에포크**: 5개 (빠른 실험용)\n- **데이터**: 558개 (원본 5,577개의 1/10)\n- **예상 훈련 시간**: ~5-10분\n\n### ⚠️ 주의사항\n- 축소된 데이터셋이므로 성능은 원본보다 낮을 수 있음\n- 실험 및 디버깅 목적으로 최적화됨\n- 실제 운영시엔 원본 데이터셋 권장\n- 모든 결과는 Google Drive에 자동 저장\n\n### 🔄 원본 데이터셋으로 돌아가려면\n경로만 변경: `GTM-dataset-small` → `GTM-dataset`"
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}