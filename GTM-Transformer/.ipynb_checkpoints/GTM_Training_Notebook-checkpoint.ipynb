{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Š GTM (Google Trends Transformer) íŒ¨ì…˜ ë§¤ì¶œ ì˜ˆì¸¡ ëª¨ë¸\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ GTM ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ íŒ¨ì…˜ ì•„ì´í…œì˜ ë§¤ì¶œì„ ì˜ˆì¸¡í•˜ëŠ” ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ¯ ëª¨ë¸ ê°œìš”\n",
    "- **ë©€í‹°ëª¨ë‹¬ ì…ë ¥**: ì´ë¯¸ì§€, í…ìŠ¤íŠ¸(ì¹´í…Œê³ ë¦¬/ìƒ‰ìƒ/ì†Œì¬), Google Trends, ì‹œê°„ì  íŠ¹ì„±\n",
    "- **ì¶œë ¥**: í–¥í›„ 12ê°œì›” ë§¤ì¶œ ì˜ˆì¸¡\n",
    "- **ì•„í‚¤í…ì²˜**: Transformer ê¸°ë°˜ + ResNet50 + BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬ Import ë° í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "# ëª¨ë¸ import\n",
    "sys.path.append('./models')\n",
    "from models.GTM import GTM\n",
    "from models.FCN import FCN\n",
    "from dataset import ZeroShotDataset\n",
    "\n",
    "# ì‹œê°í™” ì„¤ì •\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"PyTorch ë²„ì „: {torch.__version__}\")\n",
    "print(f\"PyTorch Lightning ë²„ì „: {pl.__version__}\")\n",
    "print(f\"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ğŸ—‚ï¸ ë°ì´í„° ë¡œë”© ë° íƒìƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ê²½ë¡œ ì„¤ì •\n",
    "DATA_FOLDER = 'dataset/'\n",
    "BATCH_SIZE = 32  # ë…¸íŠ¸ë¶ì—ì„œëŠ” ì‘ì€ ë°°ì¹˜ í¬ê¸° ì‚¬ìš©\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "# ê¸°ë³¸ ë°ì´í„° ë¡œë”©\n",
    "train_df = pd.read_csv(Path(DATA_FOLDER + 'train.csv'))\n",
    "test_df = pd.read_csv(Path(DATA_FOLDER + 'test.csv'))\n",
    "gtrends = pd.read_csv(Path(DATA_FOLDER + 'gtrends.csv'), index_col=[0], parse_dates=True)\n",
    "\n",
    "# ë¼ë²¨ ë”•ì…”ë„ˆë¦¬ ë¡œë”©\n",
    "cat_dict = torch.load(Path(DATA_FOLDER + 'category_labels.pt'), weights_only=False)\n",
    "col_dict = torch.load(Path(DATA_FOLDER + 'color_labels.pt'), weights_only=False)\n",
    "fab_dict = torch.load(Path(DATA_FOLDER + 'fabric_labels.pt'), weights_only=False)\n",
    "\n",
    "print(f\"ğŸ“Š ë°ì´í„° í†µê³„:\")\n",
    "print(f\"  - í›ˆë ¨ ë°ì´í„°: {len(train_df):,}ê°œ ìƒ˜í”Œ\")\n",
    "print(f\"  - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df):,}ê°œ ìƒ˜í”Œ\")\n",
    "print(f\"  - Google Trends: {len(gtrends):,}ê°œ ì‹œì \")\n",
    "print(f\"  - ì¹´í…Œê³ ë¦¬: {len(cat_dict)}ê°œ\")\n",
    "print(f\"  - ìƒ‰ìƒ: {len(col_dict)}ê°œ\")\n",
    "print(f\"  - ì†Œì¬: {len(fab_dict)}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° íƒìƒ‰\n",
    "print(\"ğŸ” í›ˆë ¨ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "display(train_df.head())\n",
    "\n",
    "print(\"\\nğŸ“ˆ Google Trends ë°ì´í„°:\")\n",
    "display(gtrends.head())\n",
    "\n",
    "# ë§¤ì¶œ ë¶„í¬ ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# ë§¤ì¶œ íˆìŠ¤í† ê·¸ë¨\n",
    "sales_cols = [col for col in train_df.columns if col.startswith('target')]\n",
    "total_sales = train_df[sales_cols].sum(axis=1)\n",
    "axes[0].hist(total_sales, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0].set_title('ğŸ“Š ì´ ë§¤ì¶œ ë¶„í¬')\n",
    "axes[0].set_xlabel('ì´ ë§¤ì¶œ')\n",
    "axes[0].set_ylabel('ë¹ˆë„')\n",
    "\n",
    "# ì›”ë³„ í‰ê·  ë§¤ì¶œ\n",
    "monthly_avg = train_df[sales_cols].mean()\n",
    "axes[1].plot(range(1, 13), monthly_avg, marker='o', linewidth=2, markersize=8)\n",
    "axes[1].set_title('ğŸ“… ì›”ë³„ í‰ê·  ë§¤ì¶œ íŒ¨í„´')\n",
    "axes[1].set_xlabel('ì›”')\n",
    "axes[1].set_ylabel('í‰ê·  ë§¤ì¶œ')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xticks(range(1, 13))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ğŸ”§ ë°ì´í„°ì…‹ ë° DataLoader ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ ìƒì„±\n",
    "print(\"ğŸ”„ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...\")\n",
    "\n",
    "train_dataset = ZeroShotDataset(\n",
    "    train_df, \n",
    "    Path(DATA_FOLDER + '/images'), \n",
    "    gtrends, \n",
    "    cat_dict, \n",
    "    col_dict, \n",
    "    fab_dict, \n",
    "    trend_len=52, \n",
    "    num_trends=3\n",
    ")\n",
    "\n",
    "test_dataset = ZeroShotDataset(\n",
    "    test_df, \n",
    "    Path(DATA_FOLDER + '/images'), \n",
    "    gtrends, \n",
    "    cat_dict, \n",
    "    col_dict, \n",
    "    fab_dict, \n",
    "    trend_len=52, \n",
    "    num_trends=3\n",
    ")\n",
    "\n",
    "# DataLoader ìƒì„±\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "print(f\"âœ… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!\")\n",
    "print(f\"  - í›ˆë ¨ ë°°ì¹˜ ìˆ˜: {len(train_loader)}\")\n",
    "print(f\"  - í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ìˆ˜: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒ˜í”Œ ë°ì´í„° í™•ì¸\n",
    "print(\"ğŸ” ìƒ˜í”Œ ë°°ì¹˜ êµ¬ì¡° í™•ì¸:\")\n",
    "sample_batch = next(iter(train_loader))\n",
    "\n",
    "item_sales, category, color, fabric, temporal_features, gtrends_batch, images = sample_batch\n",
    "\n",
    "print(f\"  - ë§¤ì¶œ íƒ€ê²Ÿ: {item_sales.shape}\")\n",
    "print(f\"  - ì¹´í…Œê³ ë¦¬: {category.shape}\")\n",
    "print(f\"  - ìƒ‰ìƒ: {color.shape}\")\n",
    "print(f\"  - ì†Œì¬: {fabric.shape}\")\n",
    "print(f\"  - ì‹œê°„ íŠ¹ì„±: {temporal_features.shape}\")\n",
    "print(f\"  - Google Trends: {gtrends_batch.shape}\")\n",
    "print(f\"  - ì´ë¯¸ì§€: {images.shape}\")\n",
    "\n",
    "# ì²« ë²ˆì§¸ ìƒ˜í”Œì˜ ì¹´í…Œê³ ë¦¬, ìƒ‰ìƒ, ì†Œì¬ í™•ì¸\n",
    "print(f\"\\nğŸ“‹ ì²« ë²ˆì§¸ ìƒ˜í”Œ ì •ë³´:\")\n",
    "print(f\"  - ì¹´í…Œê³ ë¦¬ ID: {category[0].item()}\")\n",
    "print(f\"  - ìƒ‰ìƒ ID: {color[0].item()}\")\n",
    "print(f\"  - ì†Œì¬ ID: {fabric[0].item()}\")\n",
    "print(f\"  - ì‹¤ì œ ë§¤ì¶œ (12ê°œì›”): {item_sales[0].numpy()[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ğŸ—ï¸ GTM ëª¨ë¸ ìƒì„± ë° ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "MODEL_CONFIG = {\n",
    "    'embedding_dim': 32,\n",
    "    'hidden_dim': 64,\n",
    "    'output_dim': 12,  # 12ê°œì›” ì˜ˆì¸¡\n",
    "    'num_heads': 4,\n",
    "    'num_layers': 1,\n",
    "    'use_text': True,\n",
    "    'use_img': True,\n",
    "    'cat_dict': cat_dict,\n",
    "    'col_dict': col_dict,\n",
    "    'fab_dict': fab_dict,\n",
    "    'trend_len': 52,\n",
    "    'num_trends': 3,\n",
    "    'gpu_num': 0,\n",
    "    'use_encoder_mask': 1,\n",
    "    'autoregressive': False  # Non-autoregressive ëª¨ë“œ\n",
    "}\n",
    "\n",
    "# GTM ëª¨ë¸ ìƒì„±\n",
    "model = GTM(**MODEL_CONFIG)\n",
    "\n",
    "print(\"ğŸ¯ GTM ëª¨ë¸ ìƒì„± ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“Š ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"ğŸ”§ í›ˆë ¨ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# ëª¨ë¸ êµ¬ì¡° ìš”ì•½\n",
    "print(\"\\nğŸ—ï¸ ëª¨ë¸ êµ¬ì¡°:\")\n",
    "for name, module in model.named_children():\n",
    "    print(f\"  - {name}: {module.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ğŸš€ ëª¨ë¸ í›ˆë ¨ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í›ˆë ¨ ì„¤ì •\n",
    "EPOCHS = 5  # ë…¸íŠ¸ë¶ì—ì„œëŠ” ì§§ê²Œ í›ˆë ¨\n",
    "ACCELERATOR = 'cpu'  # GPU ì‚¬ìš© ê°€ëŠ¥ì‹œ 'gpu'ë¡œ ë³€ê²½\n",
    "DEVICES = 1\n",
    "\n",
    "# ì½œë°± ì„¤ì •\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='./checkpoints/',\n",
    "    filename='gtm-{epoch:02d}-{val_mae:.2f}',\n",
    "    monitor='val_mae',\n",
    "    mode='min',\n",
    "    save_top_k=3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# ë¡œê±° ì„¤ì •\n",
    "csv_logger = CSVLogger(\n",
    "    save_dir='./logs/',\n",
    "    name='gtm_training'\n",
    ")\n",
    "\n",
    "# Trainer ì„¤ì •\n",
    "trainer = pl.Trainer(\n",
    "    devices=DEVICES,\n",
    "    accelerator=ACCELERATOR,\n",
    "    max_epochs=EPOCHS,\n",
    "    check_val_every_n_epoch=1,  # ë§¤ epochë§ˆë‹¤ validation\n",
    "    logger=csv_logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    enable_progress_bar=True,\n",
    "    log_every_n_steps=10\n",
    ")\n",
    "\n",
    "print(\"âš™ï¸ í›ˆë ¨ ì„¤ì • ì™„ë£Œ!\")\n",
    "print(f\"  - Epochs: {EPOCHS}\")\n",
    "print(f\"  - ê°€ì†ê¸°: {ACCELERATOR}\")\n",
    "print(f\"  - ë””ë°”ì´ìŠ¤: {DEVICES}\")\n",
    "print(f\"  - ì²´í¬í¬ì¸íŠ¸ ì €ì¥: ./checkpoints/\")\n",
    "print(f\"  - ë¡œê·¸ ì €ì¥: ./logs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ğŸ“ ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í›ˆë ¨ ì‹œì‘\n",
    "print(\"ğŸš€ GTM ëª¨ë¸ í›ˆë ¨ ì‹œì‘!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# í›ˆë ¨ ì‹¤í–‰\n",
    "trainer.fit(\n",
    "    model, \n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=test_loader\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ‰ í›ˆë ¨ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ğŸ“ˆ í›ˆë ¨ ê²°ê³¼ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í›ˆë ¨ ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "log_dir = './logs/gtm_training/'\n",
    "version_dirs = [d for d in os.listdir(log_dir) if d.startswith('version_')]\n",
    "latest_version = max(version_dirs, key=lambda x: int(x.split('_')[1]))\n",
    "metrics_path = os.path.join(log_dir, latest_version, 'metrics.csv')\n",
    "\n",
    "if os.path.exists(metrics_path):\n",
    "    metrics_df = pd.read_csv(metrics_path)\n",
    "    \n",
    "    # í›ˆë ¨/ê²€ì¦ ì†ì‹¤ ì‹œê°í™”\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss í”Œë¡¯\n",
    "    train_loss = metrics_df.dropna(subset=['train_loss'])\n",
    "    val_loss = metrics_df.dropna(subset=['val_loss'])\n",
    "    \n",
    "    axes[0].plot(train_loss['step'], train_loss['train_loss'], label='Training Loss', alpha=0.7)\n",
    "    axes[0].plot(val_loss['step'], val_loss['val_loss'], label='Validation Loss', marker='o')\n",
    "    axes[0].set_title('ğŸ“‰ Training/Validation Loss')\n",
    "    axes[0].set_xlabel('Steps')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # MAE í”Œë¡¯\n",
    "    val_mae = metrics_df.dropna(subset=['val_mae'])\n",
    "    axes[1].plot(val_mae['step'], val_mae['val_mae'], label='Validation MAE', marker='s', color='red')\n",
    "    axes[1].set_title('ğŸ“Š Validation MAE')\n",
    "    axes[1].set_xlabel('Steps')\n",
    "    axes[1].set_ylabel('MAE')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ìµœì¢… ë©”íŠ¸ë¦­ ì¶œë ¥\n",
    "    final_train_loss = train_loss['train_loss'].iloc[-1] if not train_loss.empty else 'N/A'\n",
    "    final_val_loss = val_loss['val_loss'].iloc[-1] if not val_loss.empty else 'N/A'\n",
    "    final_val_mae = val_mae['val_mae'].iloc[-1] if not val_mae.empty else 'N/A'\n",
    "    \n",
    "    print(\"ğŸ¯ ìµœì¢… ì„±ëŠ¥ ì§€í‘œ:\")\n",
    "    print(f\"  - ìµœì¢… í›ˆë ¨ ì†ì‹¤: {final_train_loss}\")\n",
    "    print(f\"  - ìµœì¢… ê²€ì¦ ì†ì‹¤: {final_val_loss}\")\n",
    "    print(f\"  - ìµœì¢… ê²€ì¦ MAE: {final_val_mae}\")\n",
    "else:\n",
    "    print(\"âš ï¸ í›ˆë ¨ ë¡œê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ğŸ”® ëª¨ë¸ ì˜ˆì¸¡ ë° ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ì„ evaluation ëª¨ë“œë¡œ ì„¤ì •\n",
    "model.eval()\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°°ì¹˜ì—ì„œ ëª‡ ê°œ ìƒ˜í”Œ ì˜ˆì¸¡\n",
    "with torch.no_grad():\n",
    "    sample_batch = next(iter(test_loader))\n",
    "    item_sales, category, color, fabric, temporal_features, gtrends_batch, images = sample_batch\n",
    "    \n",
    "    # ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "    predictions, attention_weights = model(category, color, fabric, temporal_features, gtrends_batch, images)\n",
    "    \n",
    "    # ì •ê·œí™” í•´ì œ (1065ëŠ” ì •ê·œí™” íŒ©í„°)\n",
    "    actual_sales = item_sales * 1065\n",
    "    predicted_sales = predictions * 1065\n",
    "\n",
    "print(f\"ğŸ”® ì˜ˆì¸¡ ê²°ê³¼ (ë°°ì¹˜ í¬ê¸°: {len(predictions)})\")\n",
    "print(f\"  - ì˜ˆì¸¡ í˜•íƒœ: {predictions.shape}\")\n",
    "print(f\"  - ì‹¤ì œ ê°’ ë²”ìœ„: {actual_sales.min():.2f} ~ {actual_sales.max():.2f}\")\n",
    "print(f\"  - ì˜ˆì¸¡ ê°’ ë²”ìœ„: {predicted_sales.min():.2f} ~ {predicted_sales.max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°œë³„ ìƒ˜í”Œ ì˜ˆì¸¡ ì‹œê°í™” (ì²˜ìŒ 6ê°œ ìƒ˜í”Œ)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "for i in range(min(6, len(predictions))):\n",
    "    actual = actual_sales[i].numpy()\n",
    "    predicted = predicted_sales[i].numpy()\n",
    "    \n",
    "    axes[i].plot(months, actual, label='ì‹¤ì œ ë§¤ì¶œ', marker='o', linewidth=2, markersize=6)\n",
    "    axes[i].plot(months, predicted, label='ì˜ˆì¸¡ ë§¤ì¶œ', marker='s', linewidth=2, markersize=6, alpha=0.8)\n",
    "    axes[i].set_title(f'ìƒ˜í”Œ {i+1}\\nì¹´í…Œê³ ë¦¬: {category[i].item()}, ìƒ‰ìƒ: {color[i].item()}')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # MAE ê³„ì‚°\n",
    "    mae = np.mean(np.abs(actual - predicted))\n",
    "    axes[i].text(0.02, 0.98, f'MAE: {mae:.1f}', transform=axes[i].transAxes, \n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7),\n",
    "                verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€\n",
    "mae_per_sample = np.mean(np.abs(actual_sales.numpy() - predicted_sales.numpy()), axis=1)\n",
    "overall_mae = np.mean(mae_per_sample)\n",
    "mse = np.mean((actual_sales.numpy() - predicted_sales.numpy()) ** 2)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"ğŸ“Š ì „ì²´ ì˜ˆì¸¡ ì„±ëŠ¥ (ë°°ì¹˜):\")\n",
    "print(f\"  - í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (MAE): {overall_mae:.2f}\")\n",
    "print(f\"  - í‰ê·  ì œê³± ì˜¤ì°¨ (MSE): {mse:.2f}\")\n",
    "print(f\"  - í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (RMSE): {rmse:.2f}\")\n",
    "\n",
    "# ì˜ˆì¸¡ vs ì‹¤ì œ ì‚°ì ë„\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(actual_sales.numpy().flatten(), predicted_sales.numpy().flatten(), \n",
    "           alpha=0.6, s=20, edgecolor='black', linewidth=0.5)\n",
    "plt.plot([actual_sales.min(), actual_sales.max()], \n",
    "         [actual_sales.min(), actual_sales.max()], \n",
    "         'r--', linewidth=2, label='Perfect Prediction')\n",
    "plt.xlabel('ì‹¤ì œ ë§¤ì¶œ')\n",
    "plt.ylabel('ì˜ˆì¸¡ ë§¤ì¶œ')\n",
    "plt.title('ğŸ¯ ì˜ˆì¸¡ vs ì‹¤ì œ ë§¤ì¶œ (ì‚°ì ë„)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# RÂ² ê³„ì‚°\n",
    "from scipy.stats import pearsonr\n",
    "correlation, p_value = pearsonr(actual_sales.numpy().flatten(), predicted_sales.numpy().flatten())\n",
    "plt.text(0.05, 0.95, f'ìƒê´€ê³„ìˆ˜: {correlation:.3f}\\np-value: {p_value:.2e}', \n",
    "         transform=plt.gca().transAxes, bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightblue\", alpha=0.8),\n",
    "         verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ğŸ’¾ ëª¨ë¸ ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì €ì¥\n",
    "model_save_path = './saved_models/gtm_model.pth'\n",
    "os.makedirs('./saved_models/', exist_ok=True)\n",
    "\n",
    "# PyTorch Lightning ì²´í¬í¬ì¸íŠ¸ ì €ì¥\n",
    "trainer.save_checkpoint(model_save_path.replace('.pth', '_lightning.ckpt'))\n",
    "\n",
    "# ì¼ë°˜ PyTorch ëª¨ë¸ ì €ì¥\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_config': MODEL_CONFIG,\n",
    "    'final_mae': overall_mae\n",
    "}, model_save_path)\n",
    "\n",
    "print(f\"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ!\")\n",
    "print(f\"  - Lightning ì²´í¬í¬ì¸íŠ¸: {model_save_path.replace('.pth', '_lightning.ckpt')}\")\n",
    "print(f\"  - PyTorch ëª¨ë¸: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì˜ˆì‹œ\n",
    "def load_gtm_model(model_path, config):\n",
    "    \"\"\"ì €ì¥ëœ GTM ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    model = GTM(**config)\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# ë¶ˆëŸ¬ì˜¤ê¸° í…ŒìŠ¤íŠ¸\n",
    "loaded_model = load_gtm_model(model_save_path, MODEL_CONFIG)\n",
    "print(\"âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° í…ŒìŠ¤íŠ¸ ì„±ê³µ!\")\n",
    "\n",
    "# ë¶ˆëŸ¬ì˜¨ ëª¨ë¸ë¡œ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸\n",
    "with torch.no_grad():\n",
    "    test_pred, _ = loaded_model(category[:5], color[:5], fabric[:5], \n",
    "                               temporal_features[:5], gtrends_batch[:5], images[:5])\n",
    "    print(f\"ğŸ”® ë¶ˆëŸ¬ì˜¨ ëª¨ë¸ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸: {test_pred.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ğŸ¯ ì‚¬ìš©ì ì •ì˜ ì˜ˆì¸¡ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fashion_sales(model, category_id, color_id, fabric_id, \n",
    "                         temporal_features, gtrends_data, image_path=None):\n",
    "    \"\"\"\n",
    "    ê°œë³„ íŒ¨ì…˜ ì•„ì´í…œì˜ ë§¤ì¶œì„ ì˜ˆì¸¡í•˜ëŠ” í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "        model: í›ˆë ¨ëœ GTM ëª¨ë¸\n",
    "        category_id: ì¹´í…Œê³ ë¦¬ ID\n",
    "        color_id: ìƒ‰ìƒ ID  \n",
    "        fabric_id: ì†Œì¬ ID\n",
    "        temporal_features: ì‹œê°„ì  íŠ¹ì„± [embedding_dim]\n",
    "        gtrends_data: Google Trends ë°ì´í„° [52, 3]\n",
    "        image_path: ì´ë¯¸ì§€ ê²½ë¡œ (ì„ íƒì )\n",
    "    \n",
    "    Returns:\n",
    "        ì˜ˆì¸¡ëœ 12ê°œì›” ë§¤ì¶œ\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # ì…ë ¥ ë°ì´í„° ì¤€ë¹„ (ë°°ì¹˜ í¬ê¸° 1)\n",
    "        category = torch.tensor([category_id], dtype=torch.long)\n",
    "        color = torch.tensor([color_id], dtype=torch.long)\n",
    "        fabric = torch.tensor([fabric_id], dtype=torch.long)\n",
    "        temporal = torch.tensor([temporal_features], dtype=torch.float32)\n",
    "        gtrends = torch.tensor([gtrends_data], dtype=torch.float32)\n",
    "        \n",
    "        # ë”ë¯¸ ì´ë¯¸ì§€ (ì‹¤ì œë¡œëŠ” ì´ë¯¸ì§€ ë¡œë”© í•„ìš”)\n",
    "        images = torch.randn(1, 3, 224, 224)\n",
    "        \n",
    "        # ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "        predictions, attention = model(category, color, fabric, temporal, gtrends, images)\n",
    "        \n",
    "        # ì •ê·œí™” í•´ì œ\n",
    "        predictions_denorm = predictions * 1065\n",
    "        \n",
    "        return predictions_denorm[0].numpy()\n",
    "\n",
    "# ì˜ˆì‹œ ì˜ˆì¸¡\n",
    "example_prediction = predict_fashion_sales(\n",
    "    model=model,\n",
    "    category_id=1,\n",
    "    color_id=2, \n",
    "    fabric_id=1,\n",
    "    temporal_features=np.random.randn(32),  # ë”ë¯¸ ë°ì´í„°\n",
    "    gtrends_data=np.random.randn(52, 3)    # ë”ë¯¸ ë°ì´í„°\n",
    ")\n",
    "\n",
    "print(\"ğŸ”® ì‚¬ìš©ì ì •ì˜ ì˜ˆì¸¡ ì˜ˆì‹œ:\")\n",
    "print(f\"  - ì…ë ¥: ì¹´í…Œê³ ë¦¬=1, ìƒ‰ìƒ=2, ì†Œì¬=1\")\n",
    "print(f\"  - 12ê°œì›” ì˜ˆì¸¡ ë§¤ì¶œ: {example_prediction}\")\n",
    "\n",
    "# ì‹œê°í™”\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(months, example_prediction, marker='o', linewidth=3, markersize=8, color='purple')\n",
    "plt.title('ğŸ”® ì‚¬ìš©ì ì •ì˜ íŒ¨ì…˜ ì•„ì´í…œ ë§¤ì¶œ ì˜ˆì¸¡')\n",
    "plt.xlabel('ì›”')\n",
    "plt.ylabel('ì˜ˆì¸¡ ë§¤ì¶œ')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ ìš”ì•½ ë° ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "### âœ… ì™„ë£Œëœ ì‘ì—…\n",
    "1. **ë°ì´í„° ë¡œë”©**: í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„°, Google Trends, ë¼ë²¨ ë”•ì…”ë„ˆë¦¬\n",
    "2. **ëª¨ë¸ êµ¬ì¶•**: GTM Transformer ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸\n",
    "3. **í›ˆë ¨**: PyTorch Lightningì„ ì‚¬ìš©í•œ íš¨ìœ¨ì  í›ˆë ¨\n",
    "4. **í‰ê°€**: ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° ë° ì‹œê°í™”\n",
    "5. **ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°**: ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬\n",
    "\n",
    "### ğŸš€ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ\n",
    "1. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**: ë” ë‚˜ì€ ì„±ëŠ¥ì„ ìœ„í•œ íŒŒë¼ë¯¸í„° ìµœì í™”\n",
    "2. **ë” ê¸´ í›ˆë ¨**: epoch ìˆ˜ë¥¼ ëŠ˜ë ¤ ë” ì¢‹ì€ ìˆ˜ë ´\n",
    "3. **ì•™ìƒë¸”**: ì—¬ëŸ¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°í•©\n",
    "4. **ì‹¤ì‹œê°„ ì¶”ë¡ **: ì›¹ APIë‚˜ ì„œë¹„ìŠ¤ë¡œ ë°°í¬\n",
    "5. **ì¶”ê°€ íŠ¹ì„±**: ê²½ì œ ì§€í‘œ, ì†Œì…œë¯¸ë””ì–´ ë°ì´í„° ë“± ì¶”ê°€ ì…ë ¥\n",
    "\n",
    "### ğŸ“Š í˜„ì¬ ì„±ëŠ¥\n",
    "- **ëª¨ë¸**: GTM (Google Trends Transformer)\n",
    "- **ì…ë ¥**: ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ + Google Trends + ì‹œê°„ íŠ¹ì„±\n",
    "- **ì¶œë ¥**: 12ê°œì›” ë§¤ì¶œ ì˜ˆì¸¡\n",
    "- **ì„±ëŠ¥**: Validation MAE ~70 (ì •ê·œí™”ëœ ìŠ¤ì¼€ì¼)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}